# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     cell_metadata_filter: -all
#     comment_magics: true
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.11.4
#   kernelspec:
#     display_name: Python 3 (ipykernel)
#     language: python
#     name: python3
# ---

# %% [markdown]
# ## Identifying transversal skills
# Get skills co-occurences and find the most and least transversal ones.
# Might make sense to do this at a level C or D level rather than individual skills (as there is perhaps a lot of overlap).

# %%
# cd ../../../..

# %%
from skills_taxonomy_v2.getters.s3_data import load_s3_data

# %%
from collections import Counter, defaultdict
import json
from itertools import chain, combinations
from tqdm import tqdm
import random

from sklearn.metrics.pairwise import cosine_similarity
import networkx as nx
import plotly.graph_objects as go
import plotly
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import boto3
from ipywidgets import interact
import bokeh.plotting as bpl
from bokeh.plotting import ColumnDataSource, figure, output_file, show, from_networkx, gridplot
from bokeh.models import (
    ResetTool,
    BoxZoomTool,
    WheelZoomTool,
    HoverTool,
    SaveTool,
    Label,
    CategoricalColorMapper,
    ColorBar,
    ColumnDataSource,
    LinearColorMapper,
    Circle,
    MultiLine,
    Plot,
    Range1d,
    Title
)

from bokeh.io import output_file, reset_output, save, export_png, show, push_notebook
from bokeh.resources import CDN
from bokeh.embed import file_html
from bokeh.palettes import Plasma, magma, cividis, inferno, plasma, viridis, Spectral6, Turbo256, Spectral, Spectral4, inferno 
from bokeh.transform import linear_cmap

bpl.output_notebook()

# %%
bucket_name = "skills-taxonomy-v2"
s3 = boto3.resource("s3")

# %% [markdown]
# ## Load data

# %%
hier_structure_file = 'outputs/skills_hierarchy/2021.09.06_hierarchy_structure.json'
hier_structure = load_s3_data(s3, bucket_name, hier_structure_file)

# %%
skill_hierarchy_file = 'outputs/skills_hierarchy/2021.09.06_skills_hierarchy.json'
skill_hierarchy = load_s3_data(s3, bucket_name, skill_hierarchy_file)

# %%
sentence_data = load_s3_data(s3, bucket_name, 'outputs/skills_extraction/extracted_skills/2021.08.31_sentences_data.json')

# %%
skills_data = load_s3_data(s3, bucket_name, 'outputs/skills_extraction/extracted_skills/2021.08.31_skills_data.json')

# %%
with open('skills_taxonomy_v2/utils/2021.09.06_level_a_rename_dict.json', 'r') as f:
    level_a_rename_dict = json.load(f)

# %% [markdown]
# ### Join the hierarchy data to the sentences

# %%
sentence_data = pd.DataFrame(sentence_data)
sentence_data = sentence_data[sentence_data['Cluster number']!=-1]

# %%
sentence_data['Hierarchy level A'] = sentence_data["Cluster number"].astype(str).apply(
    lambda x: skill_hierarchy[x]['Hierarchy level A'])
sentence_data['Hierarchy level A name'] = sentence_data["Hierarchy level A"].astype(str).apply(
    lambda x: level_a_rename_dict[x])
sentence_data['Hierarchy level B'] = sentence_data["Cluster number"].astype(str).apply(
    lambda x: skill_hierarchy[x]['Hierarchy level B'])
sentence_data['Hierarchy level C'] = sentence_data["Cluster number"].astype(str).apply(
    lambda x: skill_hierarchy[x]['Hierarchy level C'])
sentence_data['Hierarchy level D'] = sentence_data["Cluster number"].astype(str).apply(
    lambda x: skill_hierarchy[x]['Hierarchy level D'])
sentence_data['Hierarchy ID'] = sentence_data["Cluster number"].astype(str).apply(
    lambda x: skill_hierarchy[x]['Hierarchy ID'])

# %%
sentence_data.head(2)

# %% [markdown]
# ## Easy way to get names of level skill groups

# %%
lev_a_name_dict = {}
lev_b_name_dict = {}
lev_c_name_dict = {}
lev_d_name_dict = {}
for lev_a_id, lev_a in hier_structure.items():
    lev_a_name_dict[lev_a_id] = lev_a['Name']
    for lev_b_id, lev_b in lev_a['Level B'].items():
        lev_b_name_dict[lev_b_id] = lev_b['Name']
        for lev_c_id, lev_c in lev_b['Level C'].items():
            lev_c_name_dict[lev_c_id] = lev_c['Name']
            for lev_d_id, lev_d in lev_c['Level D'].items():
                lev_d_name_dict[lev_d_id] = lev_d['Name']


# %% [markdown]
# ## Get skill co-occurence

# %%
def get_cooccurence_network(sentence_data, level_skill_group):
    all_skill_combinations = []
    num_one_skills = 0 
    for _, job_skills in tqdm(sentence_data.groupby('job id')):
        unique_skills = job_skills[level_skill_group].unique().tolist()
        if len(unique_skills)!=1:
            all_skill_combinations += list(combinations(sorted(unique_skills), 2))
        else:
            num_one_skills +=1
            
    print(f"{num_one_skills} job adverts had only one skill")
    print(f"{len(all_skill_combinations)} skill pairs in job adverts")
    
    edge_list = pd.DataFrame(all_skill_combinations, columns=["source", "target"])
    edge_list["weight"] = 1
    edge_list_weighted = (
            edge_list.groupby(["source", "target"])["weight"].sum().reset_index(drop=False)
        )
    
    print(f"{len(edge_list_weighted)} unique skill pairs in job adverts")
    
    # Build network
    net = nx.from_pandas_edgelist(edge_list_weighted, edge_attr=True)
    
    return net
    


# %% [markdown]
# ## Level D analysis

# %%
level_skill_group = 'Hierarchy level D' # Can be Cluster number
net_lev_d = get_cooccurence_network(sentence_data, level_skill_group)

# %%
edges = net_lev_d.edges(data = True)
all_weights = [w['weight'] for s,e,w in edges]
plt.hist(all_weights, bins = 100);

# %%
print(f"{round(len([v for v in all_weights if v==1])*100/len(all_weights),2)}% of the edges have a weighting of 1")
max_edge_weight = 10
print(f"{round(len([v for v in all_weights if v>max_edge_weight])*100/len(all_weights),2)}% of the edges have a weighting of more than {max_edge_weight}") 

# %% [markdown]
# ## Level C analysis

# %%
level_skill_group = 'Hierarchy level C' # Can be Cluster number
net_lev_c = get_cooccurence_network(sentence_data, level_skill_group)

# %%
edges = net_lev_c.edges(data = True)
all_weights = [w['weight'] for s,e,w in edges]
plt.hist(all_weights, bins = 100, color = 'gray');

# %%
print(f"{round(len([v for v in all_weights if v==1])*100/len(all_weights),2)}% of the edges have a weighting of 1")
max_edge_weight = 10
print(f"{round(len([v for v in all_weights if v>max_edge_weight])*100/len(all_weights),2)}% of the edges have a weighting of more than {max_edge_weight}") 

# %% [markdown]
# ### Level B

# %%
level_skill_group = 'Hierarchy level B' # Can be Cluster number
net_lev_b = get_cooccurence_network(sentence_data, level_skill_group)

# %%
edges = net_lev_b.edges(data = True)
all_weights = [w['weight'] for s,e,w in edges]
plt.hist(all_weights, bins = 100);

# %%
print(f"{round(len([v for v in all_weights if v==1])*100/len(all_weights),2)}% of the edges have a weighting of 1")
max_edge_weight = 10
print(f"{round(len([v for v in all_weights if v>max_edge_weight])*100/len(all_weights),2)}% of the edges have a weighting of more than {max_edge_weight}") 

# %% [markdown]
# ## Plot networks

# %%
# All the edges

max_weight = max([net_lev_c.get_edge_data(a,b)['weight'] for a, b in net_lev_c.edges()])
min_weight = min([net_lev_c.get_edge_data(a,b)['weight'] for a, b in net_lev_c.edges()])
linewidth_max = 0.5
linewidth_min = 0.01

grad = (linewidth_max-linewidth_min)/(max_weight-min_weight)


# Show with Bokeh
plot = Plot(plot_width=500, plot_height=500)
plot.title.text = "Level C skill groups co-occurence network"

node_hover_tool = HoverTool(tooltips=[("Skill", "@skill")])
plot.add_tools(node_hover_tool, BoxZoomTool(), ResetTool(), WheelZoomTool(), SaveTool())

graph_renderer = from_networkx(net_lev_c, nx.spring_layout, scale=1, center=(0, 0))

graph_renderer.node_renderer.glyph = Circle(
    size=3, fill_color="orange", line_color=None)#Spectral4[0])

graph_renderer.edge_renderer.data_source.data["line_width"] = [
    net_lev_c.get_edge_data(a,b)['weight']*grad + linewidth_min for a, b in net_lev_c.edges()]
graph_renderer.edge_renderer.glyph.line_width = {'field': 'line_width'}

plot.renderers.append(graph_renderer)

show(plot, notebook_handle=True)

# %% [markdown]
# ### Only plot edges where weight>1

# %%
keepedges = (
    (s,e) for s,e,w in net_lev_c.edges(data = True) if w['weight']>40)
net_lev_c_filt = net_lev_c.edge_subgraph(keepedges)

# %%
max_weight = max([net_lev_c_filt.get_edge_data(a,b)['weight'] for a, b in net_lev_c_filt.edges()])
min_weight = min([net_lev_c_filt.get_edge_data(a,b)['weight'] for a, b in net_lev_c_filt.edges()])
linewidth_max = 0.5
linewidth_min = 0.01

grad = (linewidth_max-linewidth_min)/(max_weight-min_weight)


# Show with Bokeh
plot = Plot(plot_width=500, plot_height=500)
plot.title.text = "Level C skill groups co-occurence network - only high weights kept in"

node_hover_tool = HoverTool(tooltips=[("Skill", "@skill")])
plot.add_tools(node_hover_tool, BoxZoomTool(), ResetTool(), WheelZoomTool(), SaveTool())

graph_renderer = from_networkx(net_lev_c_filt, nx.spring_layout, scale=1, center=(0, 0))

graph_renderer.node_renderer.glyph = Circle(
    size=3, fill_color="orange", line_color=None)#Spectral4[0])

graph_renderer.edge_renderer.data_source.data["line_width"] = [
    net_lev_c_filt.get_edge_data(a,b)['weight']*grad + linewidth_min for a, b in net_lev_c_filt.edges()]
graph_renderer.edge_renderer.glyph.line_width = {'field': 'line_width'}

plot.renderers.append(graph_renderer)

show(plot, notebook_handle=True)

# %% [markdown]
# ### Level B network

# %%
max_weight = max([net_lev_b.get_edge_data(a,b)['weight'] for a, b in net_lev_b.edges()])
min_weight = min([net_lev_b.get_edge_data(a,b)['weight'] for a, b in net_lev_b.edges()])
linewidth_max = 0.5
linewidth_min = 0.01

grad = (linewidth_max-linewidth_min)/(max_weight-min_weight)


# Show with Bokeh
plot = Plot(plot_width=400, plot_height=400)
plot.title.text = "Level B skill groups co-occurence network"

node_hover_tool = HoverTool(tooltips=[("Skill", "@skill")])
plot.add_tools(node_hover_tool, BoxZoomTool(), ResetTool(), WheelZoomTool(), SaveTool())

graph_renderer = from_networkx(net_lev_b, nx.spring_layout, scale=1, center=(0, 0))

graph_renderer.node_renderer.glyph = Circle(size=3, fill_color="orange", line_color=None)#Spectral4[0])

graph_renderer.edge_renderer.data_source.data["line_width"] = [
    net_lev_b.get_edge_data(a,b)['weight']*grad + linewidth_min for a, b in net_lev_b.edges()]
graph_renderer.edge_renderer.glyph.line_width = {'field': 'line_width'}


plot.renderers.append(graph_renderer)

show(plot, notebook_handle=True)

# %%
# Show with Bokeh
plot = Plot(plot_width=300, plot_height=300)
plot.title.text = "Level A skill groups co-occurence network"

node_hover_tool = HoverTool(tooltips=[("Skill", "@skill")])
plot.add_tools(node_hover_tool, BoxZoomTool(), ResetTool(), WheelZoomTool(), SaveTool())

graph_renderer = from_networkx(net_lev_a, nx.spring_layout, scale=1, center=(0, 0))

graph_renderer.node_renderer.glyph = Circle(size=3, fill_color="red", line_color=None)#Spectral4[0])
graph_renderer.edge_renderer.glyph = MultiLine(
    line_color="black", line_alpha=0.1, line_width=0.2)
plot.renderers.append(graph_renderer)

show(plot, notebook_handle=True)


# %% [markdown]
# ## Extract tranversal skills
#
# From original report:
# - Eigenvector centrality is a measure of vertex influence, so if a vertex is connected to vertices with a high number of degrees, its centrality will be high (Austin, 2006). 
# - The local clustering coefficient reflects how embedded the vertex is in its neighbourhood. If one vertex has a lower local clustering coefficient than another, it implies that fewer of that vertex’s neighbours are connected to each other (Watts and Strogatz, 1998). 
# - We argue that a highly transversal skill is likely to have a high eigenvector centrality and a low local clustering coefficient, since the vertices they connect have relatively few other connections in common

# %%
def get_transversal_skills(net, level_skill_group):
    centrality = nx.eigenvector_centrality(net)
    clustering_coeff = nx.clustering(net)
    
    skill_group_scores = pd.concat([
        pd.DataFrame.from_dict(centrality, orient='index', columns=['centrality']),
        pd.DataFrame.from_dict(clustering_coeff, orient='index', columns=['clustering_coeff'])], axis=1 
    )
    
    skill_group_names = []
    for skill_group_num in skill_group_scores.index:
        if level_skill_group == 'Hierarchy level A':
            skill_group_names.append(lev_a_name_dict[str(skill_group_num)])
        elif level_skill_group == 'Hierarchy level B':
            skill_group_names.append(lev_b_name_dict[str(skill_group_num)])
        elif level_skill_group == 'Hierarchy level C':
            skill_group_names.append(lev_c_name_dict[str(skill_group_num)])
        elif level_skill_group == 'Hierarchy level D':
            skill_group_names.append(lev_d_name_dict[str(skill_group_num)])
        elif level_skill_group == 'Cluster number':
            skill_group_names.append(skills_data[str(skill_group_num)]['Skills name'])

    skill_group_scores[f"{level_skill_group} name"] = skill_group_names
    return skill_group_scores


# %%
def print_trans_skills(skill_group_scores, level_skill_group, cent_min, clust_max):

    transversal_skills = skill_group_scores[
        (skill_group_scores['centrality']>cent_min) & (skill_group_scores['clustering_coeff']<clust_max)
    ].index.tolist()
    
    transversal_skills_names = {}
    for skill_group_num in transversal_skills:
        if level_skill_group == 'Hierarchy level A':
            skill_group_name = lev_a_name_dict[str(skill_group_num)]
        elif level_skill_group == 'Hierarchy level B':
            skill_group_name = lev_b_name_dict[str(skill_group_num)]
        elif level_skill_group == 'Hierarchy level C':
            skill_group_name = lev_c_name_dict[str(skill_group_num)]
        elif level_skill_group == 'Hierarchy level D':
            skill_group_name = lev_d_name_dict[str(skill_group_num)]
        elif level_skill_group == 'Cluster number':
            skill_group_name = skills_data[str(skill_group_num)]['Skills name']
        transversal_skills_names[skill_group_num] = skill_group_name
        
    return transversal_skills_names



# %%
def print_untrans_skills(skill_group_scores, level_skill_group, cent_max, clust_min):

    untransversal_skills = skill_group_scores[
        (skill_group_scores['centrality']<cent_max) & (skill_group_scores['clustering_coeff']>clust_min)
    ].index.tolist()
    
    untransversal_skills_names = {}
    for skill_group_num in untransversal_skills:
        if level_skill_group == 'Hierarchy level A':
            skill_group_name = lev_a_name_dict[str(skill_group_num)]
        elif level_skill_group == 'Hierarchy level B':
            skill_group_name = lev_b_name_dict[str(skill_group_num)]
        elif level_skill_group == 'Hierarchy level C':
            skill_group_name = lev_c_name_dict[str(skill_group_num)]
        elif level_skill_group == 'Hierarchy level D':
            skill_group_name = lev_d_name_dict[str(skill_group_num)]
        elif level_skill_group == 'Cluster number':
            skill_group_name = skills_data[str(skill_group_num)]['Skills name']
        untransversal_skills_names[skill_group_num] = skill_group_name
        
    return untransversal_skills_names



# %% [markdown]
# ## Level D

# %%
level_d_skill_group_scores = get_transversal_skills(net_lev_d, 'Hierarchy level D')

# %%
# highly transversal skill = high centrality and a low local clustering coefficient
ax = level_d_skill_group_scores.plot.scatter(
    'centrality', 'clustering_coeff', figsize=(5,5), color='black', alpha=0.6,
    title=f"Centrality score and local clustering coefficient\nfor Hierarchy level D skill groups",
    xlabel="Eigenvector centrality", ylabel="Local clustering coefficient"
);
ax.axvline(0.14, color='orange', linestyle='--')
ax.axhline(0.7, color='orange', linestyle='--')


# %%
cent_min = 0.14
clust_max = 0.7
level_d_skill_group_scores[
    (level_d_skill_group_scores['centrality']>cent_min) & (level_d_skill_group_scores['clustering_coeff']<clust_max)
]

# %%
cent_max = 0.06
clust_min = 0.8
level_d_skill_group_scores[
    (level_d_skill_group_scores['centrality']<cent_max) & (level_d_skill_group_scores['clustering_coeff']>clust_min)
]

# %% [markdown]
# ## Level C

# %%
level_c_skill_group_scores = get_transversal_skills(net_lev_c, 'Hierarchy level C')

# %%
# highly transversal skill = high centrality and a low local clustering coefficient
ax = level_c_skill_group_scores.plot.scatter(
    'centrality', 'clustering_coeff', figsize=(5,5), color='black', alpha=0.6,
    title=f"Centrality score and local clustering coefficient\nfor Hierarchy level C skill groups",
    xlabel="Eigenvector centrality", ylabel="Local clustering coefficient"
);
ax.axvline(0.065, color='orange', linestyle='--')
ax.axhline(0.93, color='orange', linestyle='--')


# %%
cent_min = 0.065
clust_max = 0.93
level_c_skill_group_scores[
    (level_c_skill_group_scores['centrality']>cent_min) & (level_c_skill_group_scores['clustering_coeff']<clust_max)
]

# %%
cent_max = 0.05
clust_min = 0.95
level_c_skill_group_scores[
    (level_c_skill_group_scores['centrality']<cent_max) & (level_c_skill_group_scores['clustering_coeff']>clust_min)
]

# %% [markdown]
# ## Level B

# %%
level_b_skill_group_scores = get_transversal_skills(net_lev_b, 'Hierarchy level B')

# %%
# highly transversal skill = high centrality and a low local clustering coefficient
ax = level_b_skill_group_scores.plot.scatter(
    'centrality', 'clustering_coeff', figsize=(5,5), color='black', alpha=0.6,
    title=f"Centrality score and local clustering coefficient\nfor Hierarchy level B skill groups",
    xlabel="Eigenvector centrality", ylabel="Local clustering coefficient"
);
ax.axvline(0.12, color='orange', linestyle='--')
ax.axhline(0.96, color='orange', linestyle='--')


# %%
cent_min = 0.12
clust_max = 0.96
level_b_skill_group_scores[
    (level_b_skill_group_scores['centrality']>cent_min) & (level_b_skill_group_scores['clustering_coeff']<clust_max)
]

# %%
cent_max = 0.1
clust_min = 0.98
level_b_skill_group_scores[
    (level_b_skill_group_scores['centrality']<cent_max) & (level_b_skill_group_scores['clustering_coeff']>clust_min)
]

# %% [markdown]
# ## Plots together

# %%
fig, axes = plt.subplots(1,2, figsize=(10,5))  

level_b_skill_group_scores.plot.scatter(
    'centrality', 'clustering_coeff', color='black', alpha=0.6,
    title=f"Centrality score and local clustering coefficient\nfor Hierarchy level B skill groups",
    xlabel="Eigenvector centrality", ylabel="Local clustering coefficient",
    ax=axes[0]
);
axes[0].axvline(0.12, color='orange', linestyle='--')
axes[0].axhline(0.96, color='orange', linestyle='--')


level_c_skill_group_scores.plot.scatter(
    'centrality', 'clustering_coeff', color='black', alpha=0.6,
    title=f"Centrality score and local clustering coefficient\nfor Hierarchy level C skill groups",
    xlabel="Eigenvector centrality", ylabel="Local clustering coefficient",
    ax=axes[1]
);
axes[1].axvline(0.065, color='orange', linestyle='--')
axes[1].axhline(0.93, color='orange', linestyle='--')


plt.tight_layout()

plt.savefig('outputs/skills_taxonomy/transversal/transversal_skills_scatter.pdf',bbox_inches='tight')



# %%
fig, axes = plt.subplots(1,1, figsize=(5,5))  

level_c_skill_group_scores.plot.scatter(
    'centrality', 'clustering_coeff', color='black', alpha=0.6,
    title=f"Centrality score and local clustering coefficient\nfor Hierarchy level C skill groups",
    xlabel="Eigenvector centrality", ylabel="Local clustering coefficient",
    ax=axes
);
axes.axvline(0.065, color='orange', linestyle='--')
axes.axhline(0.93, color='orange', linestyle='--')

plt.tight_layout()

plt.savefig('outputs/skills_taxonomy/transversal/transversal_skills_scatter_levc.pdf',bbox_inches='tight')


# %%
cent_min = 0.065
clust_max = 0.93
trans_skills_levc = level_c_skill_group_scores[
    (level_c_skill_group_scores['centrality']>cent_min) & (level_c_skill_group_scores['clustering_coeff']<clust_max)
]

# %%
cent_max = 0.04
clust_min = 0.96
level_c_skill_group_scores[
    (level_c_skill_group_scores['centrality']<cent_max) & (level_c_skill_group_scores['clustering_coeff']>clust_min)
]

# %%
trans_skills = trans_skills_levc.index.tolist()
trans_skills_hier = {}
for lev_a_id, lev_a in hier_structure.items():
    for lev_b_id, lev_b in lev_a['Level B'].items():
        for lev_c_id, lev_c in lev_b['Level C'].items():
            if int(lev_c_id) in trans_skills:
                trans_skills_hier[int(lev_c_id)] = {
                    "Level A": lev_a_id,
                    "Level B": lev_b_id,
                    "Level C": lev_c_id,
                    "Level A name": level_a_rename_dict[lev_a_id],
                    "Level B name": lev_b_name_dict[lev_b_id]}

# %%
trans_skills_levc = pd.concat([trans_skills_levc,pd.DataFrame(trans_skills_hier).T], axis=1)
trans_skills_levc.to_csv('outputs/skills_taxonomy/transversal/lev_c_trans_skills.csv')
trans_skills_levc

# %%
